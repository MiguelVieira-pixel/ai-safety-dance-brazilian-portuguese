"<p>The Value Alignment Problem:</p>";"<p>“How can we make AI robustly serve humane values?”</p>"
"<p>The Value Alignment Problem can be broken up into two sub-problems:</p>";"<p>What are humane values? / The Technical Alignment Problem</p>"
"<p>The Technical Alignment Problem:</p>";"<p>“How can we make AI robustly serve <em>any intended goal</em> at all?”</p>"
"<p>Common misconception about technical alignment:</p>";"<p><em>Technically</em> aligned does not mean 'humane' or 'good'! An AI can be 100% technically aligned to an inhumane user's intentions.</p>"
"<p>The Technical Alignment Problem can be broken up into two sub-problems:</p>";"<p>Problems with AI Logic (&quot;game theory&quot; problems) / Problems with AI &quot;Intuition&quot; (&quot;deep learning&quot; problems)</p>"
"<p>The two core divides in AI &amp; AI Safety:</p>";"<p>Logic 'vs' Intuition / Problems in the AI 'vs' in the Human</p>"
"<p>Response to: “AI Risk is a fringe concern”.</p>";"<p>No, top AI researchers worry about it. (For example: two pioneers of deep learning &amp; the authors of the #1 AI textbook.)</p>"
"<p>Response to: “AI Risk is about sentient/conscious AI”.</p>";"<p>No, the safety problems are more 'boring', but still important.</p>"
"<p>Name (at least) one 'boring' way AI can be unsafe:</p>";"<p>(Any of the following:) AI accomplishes its goal in a logical but unwanted way / AI learns the wrong things / AI breaks in new circumstances</p>"
"<p>Name (at least) one concrete example of catastrophic risk from advanced AI:</p>";"<p>(Any example works, but here's what I listed:) Bio-terrorism, Digital authoritariansm, Cyber-security Ransom Hell.</p>"
"<p>Response to: “AI Risk people are anti-tech Luddites”</p>";"<p>No, most of them know about the huge upsides, which is exactly why they want to prevent the huge downsides.</p>"
"<p>“Both the optimist and the pessimist contribute to society...</p>";"<p>...The optimist invents the airplane, and the pessimist invents the parachute.”</p>"
"<p>Response to: ‘But AI right now is dumb, how can it be high-risk’?</p>";"<p>It's not about AI <em>right now</em>, it's about <em>how fast</em> AI is advancing.</p>"